# ButakeroMusicBot

**ButakeroMusicBot** es un microservicio dise√±ado para la descarga, procesamiento y subida de audios desde videos de YouTube a Amazon S3. Utiliza tecnolog√≠as modernas y est√° preparado para ser desplegado en la nube, Kubernetes o localmente con Docker Compose.


## Tabla de Contenidos üìã

- [Caracter√≠sticas Principales](#caracter√≠sticas-principales)
- [Requisitos Previos](#requisitos-previos)
- [Formas de Despliegue](#formas-de-despliegue)
  - [1. Docker Compose](#1-docker-compose)
  - [2. Kubernetes](#2-kubernetes)
  - [3. AWS ECS con Terraform](#3-aws-ecs-con-terraform)
- [Endpoints del API](#endpoints-del-api)
- [Pruebas](#pruebas)
- [Explicaci√≥n de diagramas de Arquitectura](#explicaci√≥n-de-diagramas-de-arquitectura)
  - [1. Arquitectura de la Aplicaci√≥n en AWS ECS](#arquitectura-de-la-aplicaci√≥n-en-aws-ecs)
  - [2. Arquitectura en Kubernetes](#arquitectura-en-kubernetes)
---

## Caracter√≠sticas Principales

- üîç B√∫squeda de videos en YouTube por nombre o URL.
- üéß Descarga y procesamiento de audio.
- ‚òÅÔ∏è Subida de archivos de audio a Amazon S3.
- üóÉÔ∏è Registro de operaciones y metadatos en DynamoDB.
- üîÑ Sistema de reintentos en caso de fallos.
- üìä Monitoreo y m√©tricas con Prometheus/Grafana
- üîí Seguridad y autenticaci√≥n integrada

## Requisitos Previos

### Requisitos Generales

- Go 1.21 o superior
- Docker y Docker Compose
- Cuenta de AWS con acceso program√°tico
- API Key de YouTube
- Git
---

### Para Despliegue en AWS

- AWS CLI configurado
- Terraform >= 1.0
- Cuenta de AWS con permisos para:
  - ECS
  - ECR
  - S3
  - DynamoDB
  - IAM
  - VPC
  - CloudWatch

---

### Para Despliegue en Kubernetes

- Kubernetes Cluster (1.24+)
- kubectl configurado
- Helm v3
- Minikube (para desarrollo local)

---

## Formas de Despliegue

El microservicio puede ser desplegado de distintas maneras, dependiendo del entorno en el que se desee correr. A continuaci√≥n, se detallan las tres formas principales de despliegue:

### 1. Docker Compose

El despliegue con Docker Compose levanta los siguientes servicios:

- Zookeeper
- Kafka
- MongoDB
- Backend (usando el Dockerfile del proyecto)

### Configuraci√≥n Inicial

1. Docker y Docker Compose instalados en tu m√°quina.

2. Crea un archivo llamado `test_local.env`, en el directorio donde se encuentra el [docker compose](./docker-compose.yml). Este archivo tiene que tener estas variables necesarias para ejecutar el servicio localmente. Lo principal que necesitas modificar es la variable `YOUTUBE_API_KEY`:

```env
# Environment
ENVIRONMENT=local
LOCAL_STORAGE_PATH=data/audio-files
SERVICE_MAX_ATTEMPTS=7
SERVICE_TIMEOUT=2
YOUTUBE_API_KEY=TU_API_KEY_AQUI  # Modificar esto con tu API key
GIN_MODE=release

# Kafka Configuration
KAFKA_TOPIC=notification
KAFKA_BROKERS=kafka:29092
KAFKA_ENABLE_TLS=false

# Authentication
OAUTH2=false

# MongoDB Configuration
MONGO_USER=root
MONGO_PASSWORD=root
MONGO_PORT=27017
MONGO_HOST=mongodb
MONGO_DATABASE=audio_service_db
MONGO_COLLECTION_SONGS=Songs
MONGO_COLLECTION_OPERATIONS=Operations
MONGO_ENABLE_TLS=false
MONGO_REPLICA_SET_NAME=rs0

# YouTube Cookies
COOKIES_YOUTUBE=/root/yt-cookies.txt
```

#### Obtener YouTube API Key

Para obtener tu YouTube API Key, sigue estos pasos:

1. Ve a la [Google Cloud Console](https://console.cloud.google.com/)
2. Crea un nuevo proyecto o selecciona uno existente
3. Habilita la YouTube Data API v3 para tu proyecto
4. Ve a "Credenciales"
5. Crea una nueva credencial de tipo "API Key"
6. Copia la API Key generada y col√≥cala en la variable `YOUTUBE_API_KEY` del archivo `test_local.env`

3. Script de cookies de YouTube (opcional): Si encontras problemas con YouTube, como el error "Sign in to confirm your age", podes generar un archivo de cookies para evitar el bloqueo. Para ello, tenes que ejecutar previamente el script [filter_youtube_cookies.sh](filter_youtube_cookies.sh) que generar√° el archivo `yt-cookies.txt`.

```bash
bash filter_youtube_cookies.sh
```

#### Ejecutar con Docker Compose
El proyecto incluye un [docker-compose.yml](./docker-compose.yml) que levanta todos los servicios necesarios:
- Zookeeper
- Kafka
- MongoDB
- Backend (usando el Dockerfile del proyecto)

Para iniciar todos los servicios:
```bash
docker compose up -d
```

Para ver los logs de los servicios:
```bash
# Ver todos los logs
docker compose logs -f

# Ver logs de un servicio espec√≠fico
docker compose logs -f backend-application
```

Para detener los servicios:
```bash
docker compose down
```

### 2. Kubernetes

#### Prerrequisitos
- Kubernetes Cluster (1.24+)
- kubectl configurado
- Helm v3
- Minikube (para desarrollo local)

#### Configuraci√≥n de Credenciales
Antes de ejecutar el despliegue, debes configurar las credenciales en el archivo [secret.yaml](/k8s/bases/backend/download-service/secret.yaml):
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: backend-secret
  namespace: backend
type: Opaque
stringData:
  YOUTUBE_API_KEY: "${YOUTUBE_API_KEY}"  # Tu API key de YouTube
  MONGO_USER: "admin-user"     
  MONGO_PASSWORD: "root"
  YT_COOKIES: "${YT_COOKIES}"   # Cookies de YouTube (opcional)
```

#### Obtener Cookies de YouTube (Opcional)
Para evitar errores de autorizaci√≥n en YouTube ("Sign in to confirm your age"), puedes configurar cookies:
1. Ejecuta el script:
```bash
bash filter_youtube_cookies.sh
```

2. Copia el contenido generado al campo YT_COOKIES del secret.

#### Despliegue Automatizado

El proyecto incluye un script [deploy.sh](/deploy.sh) que automatiza todo el proceso de despliegue. Este script:

1. Crea los namespaces necesarios:
   - Kafka
   - MongoDB
   - Prometheus
   - Backend
   - Otros servicios

2. Configura RBAC y permisos para:
   - Prometheus
   - MongoDB

3. Instala y configura componentes esenciales:
   - Cert-Manager para gesti√≥n de certificados SSL/TLS
   - Operador de MongoDB
   - Kafka con Strimzi
   - Prometheus & Grafana para monitorizaci√≥n
   - Backend de la aplicaci√≥n

Para ejecutar el despliegue completo, simplemente ejecuta:

```bash
bash deploy.sh
```

El script se encargar√° de:
- Verificar los prerrequisitos
- Crear todos los recursos necesarios
- Esperar a que los pods est√©n listos
- Verificar el estado final del despliegue

#### Acceso Local a los Endpoints

Una vez completado el despliegue, puedes acceder a los endpoints localmente:

```bash
kubectl port-forward svc/backend-service 8080 -n backend
```

Esto te permitir√° acceder al servicio en http://localhost:8080/api/v1/health

#### Verificar el Estado del Despliegue

Para verificar el estado de los pods:

```bash
# Ver pods en el namespace backend
kubectl get pods -n backend

# Ver pods en todos los namespaces
kubectl get pods --all-namespaces
```

#### Logs y Monitoreo

Para ver los logs del backend:

```bash
# Obtener el nombre del pod
kubectl get pods -n backend

# Ver logs
kubectl logs -f backend-application-hash -n backend
```

Para acceder a Grafana:

```bash
kubectl port-forward svc/grafana 3000 -n monitoring
```

### 3. AWS ECS con Terraform

#### Prerrequisitos
- Terraform >= 1.0
- AWS CLI configurado
- Cuenta de AWS con permisos necesarios

#### Configuraci√≥n del Backend Remoto

> **Advertencia:**  
> Antes de seguir, es **obligatorio** generar las cookies con el script [filter_youtube_cookies.sh](filter_youtube_cookies.sh). Muchas IPs de las instancias de AWS est√°n **baneadas o bloqueadas** por YouTube, as√≠ que vas a tener que usar cookies v√°lidas para evitar problemas de conexi√≥n. Si vas a desplegarlo en ECS, asegurate de hacer este paso antes.

1. Crear el bucket S3:
```bash
aws s3api create-bucket \
    --bucket song-download-tf-state \
    --region us-east-1
```

2. Habilitar el versionado del bucket:
```bash
aws s3api put-bucket-versioning \
    --bucket song-download-tf-state \
    --versioning-configuration Status=Enabled
```

3. Crear la tabla DynamoDB para el bloqueo del estado:
```bash
aws dynamodb create-table \
    --table-name terraform-lock-table \
    --attribute-definitions AttributeName=LockID,AttributeType=S \
    --key-schema AttributeName=LockID,KeyType=HASH \
    --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
    --region us-east-1
```

#### Configuraci√≥n del Provider y Backend

El archivo [provider.tf](song-downloader-infra/providers.tf) debe contener:

```hcl
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
  backend "s3" {
    bucket         = "song-download-tf-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-lock-table"
    encrypt        = true
  }
}

provider "aws" {
  region = var.aws_region
}
```

#### Configuraci√≥n
1. Movete al directorio donde se encuentra los archivos .tfs:
```bash
microservices/audio_processor/song-downloader-infra
```

2. Edita el archivo [terraform.example.tfvars](song-downloader-infra/terraform.example.tfvars) con tus configuraciones:
```hcl
# Configuraci√≥n b√°sica
aws_region = "us-east-1"
project_name = "butakero-music-download"
environment = "prod"

# Configuraci√≥n del servicio
gin_mode = "release"
service_max_attempts = 5
service_timeout = 2
youtube_api_key = "TU_API_KEY_AQUI"  # Modifica esto con tu API key de YouTube
oauth2_enabled = "true"
container_port = 8080
secret_name = "butakero-audio-service-secrets"

# Tags para recursos AWS
alb_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
ecs_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
storage_s3_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
dynamodb_table_operations_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
dynamodb_table_songs_tag = {
  Project     = "music-downloader"
  Environment = "production"
}
sqs_queue_tag = {
  Project     = "music-downloader"
  Environment = "production"
}
ecr_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
networking_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
cloudwatch_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
iam_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
security_group_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
sm_tags = {
  Project     = "music-downloader"
  Environment = "production"
}
```

#### Pasos de Despliegue

1. Inicializa Terraform:
```bash
terraform init
```

2. Verifica los cambios que se realizar√°n:
```bash
terraform plan -var-file="terraform.example.tfvars"
```

3. Aplica la infraestructura:
```bash
terraform apply
```
#### Recursos Desplegados
El despliegue crear√° los siguientes recursos en AWS:

- **ECS Cluster** con Fargate
- **Application Load Balancer**
- **S3 Bucket** para almacenamiento de archivos
- **DynamoDB Tables** para operaciones y canciones
- **SQS Queue** para mensajer√≠a
- **ECR Repository** para im√°genes de contenedor
- **CloudWatch** para logs y monitoreo
- **IAM Roles** y pol√≠ticas necesarias
- **Security Groups** para control de acceso
- **VPC** y recursos de networking
- **Secrets Manager** para gesti√≥n de secretos

#### Destruir la Infraestructura

Para eliminar todos los recursos creados:
```bash
terraform destroy
```


## Endpoints del API

### 1. Iniciar el procesamiento de una canci√≥n

- **M√©todo**: POST
- **Endpoint**: `/api/audio/start`
- **Query Params**:
  - `song`: El t√≠tulo de la canci√≥n o la URL del video de YouTube.
- **Descripci√≥n**: Este endpoint inicia el procesamiento de la canci√≥n. Se puede enviar el nombre o la URL de la canci√≥n en el par√°metro song. La API buscar√° el video en YouTube, descargar√° el audio, lo procesar√° y lo subir√° a S3.

Ejemplo de solicitud:

```bash
curl -X POST "http://localhost:8080/api/v1/audio/start?song=linkin+park+the+emptiness+machine"
```

Respuesta:

```json
{
  "operation_id": "19f6c66f-26f3-4ccf-bfc7-967449a95ad4",
  "song_id": "SRXH9AbT280"
}
```

### 2. Consultar el estado de una operaci√≥n

- **M√©todo**: GET
- **Endpoint**: `/api/audio/status`
- **Query Params**:
  - `operation_id`: El ID √∫nico de la operaci√≥n iniciada.
  - `song_id`: El ID de la canci√≥n procesada.
- **Descripci√≥n**: Este endpoint devuelve el estado actual del procesamiento de audio utilizando el `operation_id` y el `song_id`. El estado incluye informaci√≥n detallada sobre la operaci√≥n.

Ejemplo de solicitud:

```bash
curl -X GET "http://localhost:8080/api/v1/audio/status?operation_id=19f6c66f-26f3-4ccf-bfc7-967449a95ad4&song_id=SRXH9AbT280"
```

Respuesta (ejemplo de operaci√≥n en curso):

```json
{
  "status": {
      "id": "19f6c66f-26f3-4ccf-bfc7-967449a95ad4",
      "sk": "SRXH9AbT280",
      "status": "iniciando",
      "message": "",
      "metadata": null,
      "file_data": null,
      "processing_date": "",
      "success": false,
      "attempts": 0,
      "failures": 0
  }
}
```

Respuesta (ejemplo de operaci√≥n finalizada):

```json
{
    "status": {
      "id": "19f6c66f-26f3-4ccf-bfc7-967449a95ad4",
      "sk": "SRXH9AbT280",
      "status": "success",
      "message": "Procesamiento exitoso",
      "metadata": {
          "id": "63f48016-78cd-4387-99b9-c38af46e8e90",
          "video_id": "SRXH9AbT280",
          "title": "The Emptiness Machine (Official Music Video) - Linkin Park",
          "duration": "PT3M21S",
          "url_youtube": "https://youtube.com/watch?v=SRXH9AbT280",
          "thumbnail": "https://i.ytimg.com/vi/SRXH9AbT280/default.jpg",
          "platform": "Youtube"
      },
      "file_data": {
          "file_path": "audio/The Emptiness Machine (Official Music Video) - Linkin Park.dca",
          "file_size": "1.44MB",
          "file_type": "audio/dca",
          "public_url": "file://data/audio-files/audio/The Emptiness Machine (Official Music Video) - Linkin Park.dca"
      },
      "processing_date": "2024-12-24T05:39:58Z",
      "success": true,
      "attempts": 1,
      "failures": 0
  }
}
```

Respuesta (ejemplo de operaci√≥n fallida):

```json
{
  "operation_id": "19f6c66f-26f3-4ccf-bfc7-967449a95ad4",
  "status": "failed",
  "error": "Descripci√≥n del error ocurrido"
}
```

## Pruebas

Para ejecutar las pruebas unitarias y de integracion del proyecto, podes correr:

```bash
go test ./...
```


## Explicaci√≥n de diagramas de Arquitectura

## Diagrama de Secuencia

![image](/images/diagrama-de-secuencia-microservicio.png)

El diagrama de secuencia ilustra el flujo de interacci√≥n entre los diferentes componentes del microservicio durante el proceso de descarga y procesamiento de audio. A continuaci√≥n, se describen los pasos clave:

1. **Cliente**: Inicia la solicitud de descarga de audio enviando la canci√≥n deseada al microservicio.
2. **Microservicio**: Recibe la solicitud y utiliza el servicio de YouTube para buscar el ID del video correspondiente a la canci√≥n.
3. **YouTube API**: Proporciona el ID del video y sus detalles (metadata) al microservicio.
4. **Microservicio**: Inicia una operaci√≥n para el procesamiento del audio y devuelve el `operation_id` y `song_id` al cliente.
5. **Proceso As√≠ncrono**: En paralelo, el microservicio procesa el audio utilizando el ID de operaci√≥n y los detalles obtenidos, permitiendo al cliente continuar con otras tareas sin esperar la finalizaci√≥n.

Este enfoque as√≠ncrono asegura que el usuario reciba una respuesta inmediata, mejorando la experiencia del usuario.

# Arquitectura de la Aplicaci√≥n en AWS ECS

![image](/images/arquitectura-microservice-aws.png)

## Componentes de la Arquitectura

### 1. VPC (Virtual Private Cloud)
Todo corre dentro de una VPC para asegurar que los recursos est√©n aislados y podamos aplicar reglas de seguridad espec√≠ficas. Esto nos permite controlar el tr√°fico y proteger los servicios.

### 2. EC2 Instance
El tr√°fico llega primero a una instancia de EC2 que act√∫a como puerta de entrada. Desde aca, la aplicacion **Nuestro Bot de musica** env√≠a requests a nuestra aplicaci√≥n **Donde se encuentra la logica de procesamiento de audio**, que son redirigidas a trav√©s de un Application Load Balancer.

### 3. Application Load Balancer (ALB)
El ALB es clave en esta arquitectura. Recibe tr√°fico HTTP en el puerto 80 y lo distribuye a un Target Group configurado para enrutar las solicitudes a las tareas de ECS. Adem√°s, tiene configurado un **health check** que verifica cada 30 segundos el estado de las tareas para garantizar que solo las instancias saludables reciban tr√°fico.

### 4. ECS Cluster y Fargate
Estamos usando Fargate, lo que significa que no tenemos que gestionar la infraestructura de los contenedores. Las tareas de ECS se ejecutan dentro del cl√∫ster, sin la necesidad de manejar instancias EC2. Esto nos permite concentrarnos en el desarrollo, y Fargate se encarga del resto.

### 5. ECS Tasks
Las tareas de ECS son donde realmente se ejecuta nuestro c√≥digo. Los contenedores est√°n corriendo en el puerto 8080, y el ALB enruta el tr√°fico hacia este puerto desde el Target Group. Cada tarea tiene permisos para interactuar con servicios como S3 y DynamoDB a trav√©s de roles IAM configurados espec√≠ficamente para esto.

#### Interacci√≥n con S3
Nuestras tareas ECS pueden acceder a S3 para subir o descargar objetos. Por ejemplo, usamos S3 para almacenar archivos multimedia por ej **.dca**. Las tareas hacen uso de la API de S3 para gestionar estos archivos.

#### Interacci√≥n con DynamoDB
Adem√°s, las tareas se conectan a DynamoDB para gestionar el estado de la aplicaci√≥n, como el seguimiento de operaciones o el almacenamiento de metadatos. DynamoDB es r√°pido y se adapta bien a las necesidades de baja latencia de nuestra aplicaci√≥n.

### 6. CloudWatch y Auto Scaling
El monitoreo est√° a cargo de CloudWatch. Configuramos m√©tricas clave, como el uso de CPU y memoria en las tareas ECS. En base a estas m√©tricas, tenemos configuradas **pol√≠ticas de Auto Scaling**, que permiten escalar horizontalmente las tareas de ECS. Esto significa que si el uso de CPU o memoria supera ciertos umbrales, autom√°ticamente se lanzan m√°s tareas para manejar el tr√°fico adicional, y se reducen cuando ya no son necesarias.

#### Configuraci√≥n del Auto Scaling
Configuramos el Auto Scaling usando CloudWatch como desencadenante. Cuando se alcanza un cierto umbral de CPU o memoria (por ejemplo, 75%), se activa la pol√≠tica que lanza nuevas tareas ECS hasta que los recursos vuelvan a estar en niveles normales. Esto asegura que nuestra aplicaci√≥n se mantenga eficiente sin desperdiciar recursos.

### 7. IAM Roles y Seguridad
Cada tarea de ECS tiene asociado un **IAM Role** que le permite acceder a servicios espec√≠ficos como S3 y DynamoDB, pero sin dar permisos innecesarios. Estos roles est√°n configurados con permisos m√≠nimos para garantizar la seguridad. Por otro lado, usamos **Security Groups** para controlar el tr√°fico entrante y saliente en la VPC, asegurando que solo el tr√°fico autorizado llegue a los contenedores.

## Flujo de Tr√°fico

1. **Applicacion bot de musica**: Env√≠a una requests desde un cliente EC2.
2. **ALB**: La solicitud llega al ALB, que se encarga de dirigir el tr√°fico al Target Group.
3. **Target Group**: Este grupo enruta el tr√°fico a las tareas de ECS corriendo en Fargate.
4. **ECS Tasks**: Las tareas procesan la solicitud y, si necesitan, acceden a S3 y DynamoDB para manejar los datos.
5. **CloudWatch**: Monitorea el rendimiento y activa pol√≠ticas de escalado si se detectan problemas de capacidad.
---

## Arquitectura en Kubernetes

![image](/images/arquitectura-k8s.png)

Nuestra aplicaci√≥n est√° desplegada en Kubernetes utilizando una arquitectura de microservicios que consta de varios componentes clave:

### Componentes Core

1. **Servicio Backend**
   - Punto de entrada para todas las solicitudes de clientes
   - Desplegado como un servicio de Kubernetes con capacidades de balanceo de carga

2. **Capa de Aplicaci√≥n**
   - Contiene los nodos de Backend en tiempo real
   - Desplegado como StatefulSet para mantener el orden de procesamiento
   - Escala horizontalmente seg√∫n la demanda

3. **Procesamiento de Mensajes**
   - Servicios de Kafka y MongoDB para el manejo y almacenamiento de mensajes
   - Utiliza PVC (Persistent Volume Claims) para persistencia de datos
   - Desplegado usando operadores de Kubernetes para gesti√≥n automatizada

### Operadores de Kubernetes

El sistema utiliza operadores especializados para gestionar aplicaciones con estado:

- **Operador Strimzi**: Gestiona los clusters de Kafka
- **Operador MongoDB**: Maneja los despliegues y escalado de MongoDB

### Stack de Monitoreo

- **Prometheus**: Recolecta m√©tricas de los servicios
- **Grafana**: Visualiza datos de monitoreo
- **Colectores de M√©tricas**:
  - Node exporter para m√©tricas del sistema
  - Service monitor para m√©tricas de aplicaci√≥n

### Almacenamiento y Gesti√≥n de Estado

- Almacenamiento persistente usando PVC para:
  - Datos de MongoDB
  - Logs de Kafka
  - Metadatos de operaciones
  - Almacenamiento de canciones

### Seguridad

- **Cert-manager**: Gesti√≥n de certificados TLS
- Comunicaci√≥n segura entre servicios usando TLS
- Pol√≠ticas de red para control de comunicaci√≥n interna

### Escalabilidad y Confiabilidad

- Componentes replicados para alta disponibilidad:
  - Clusters de Kafka con m√∫ltiples r√©plicas
  - ReplicaSets de MongoDB
  - M√∫ltiples instancias del Backend en tiempo real
